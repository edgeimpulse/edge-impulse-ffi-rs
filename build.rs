use std::env;
use std::fs;
use std::path::PathBuf;
use std::process::Command;

mod build_helpers;

fn clean_model_folder() {
    let model_dir = "model";

    // Check if model directory exists
    if !fs::metadata(model_dir).is_ok() {
        println!("Model directory does not exist, nothing to clean");
        return;
    }

    // Read all entries in the model directory
    let entries = match fs::read_dir(model_dir) {
        Ok(entries) => entries,
        Err(e) => {
            eprintln!("Failed to read model directory: {}", e);
            return;
        }
    };

    for entry in entries {
        let entry = match entry {
            Ok(entry) => entry,
            Err(e) => {
                eprintln!("Failed to read directory entry: {}", e);
                continue;
            }
        };

        let path = entry.path();
        let file_name = path.file_name().unwrap_or_default();

        // Skip README.md and .gitignore
        if file_name == "README.md" || file_name == ".gitignore" {
            continue;
        }

        // Remove the entry (file or directory)
        if path.is_dir() {
            if let Err(e) = fs::remove_dir_all(&path) {
                eprintln!("Failed to remove directory {:?}: {}", path, e);
            } else {
                println!("Removed directory: {:?}", path);
            }
        } else {
            if let Err(e) = fs::remove_file(&path) {
                eprintln!("Failed to remove file {:?}: {}", path, e);
            } else {
                println!("Removed file: {:?}", path);
            }
        }
    }

    println!("Model folder cleaned successfully. Only README.md and .gitignore remain.");
}

fn extract_and_write_model_metadata() {
    use std::collections::HashMap;
    use std::fs;
    let header_path = "model/model-parameters/model_metadata.h";
    let out_path = "src/model_metadata.rs";
    let header = fs::read_to_string(header_path).expect("Failed to read model_metadata.h");

    let mut out = String::from("// This file is @generated by build.rs. Do not edit manually.\n");
    out.push_str("// Model metadata constants extracted from model_metadata.h\n\n");

    let mut seen = HashMap::new();
    let mut raw_defs = Vec::new();

    // First pass: collect all constants and their raw values
    for line in header.lines() {
        if let Some(rest) = line.strip_prefix("#define ") {
            let mut parts = rest.splitn(3, ' ');
            let name = parts.next();
            let val = parts.next();
            let val_rest = parts.next();
            if let (Some(name), Some(val)) = (name, val) {
                let value = if let Some(rest) = val_rest {
                    // Value is everything after the name
                    format!("{} {}", val, rest).trim().to_string()
                } else {
                    val.trim().to_string()
                };
                if !(name.starts_with("EI_CLASSIFIER_") || name.starts_with("EI_ANOMALY_TYPE_")) {
                    continue;
                }
                if seen.contains_key(name) {
                    continue;
                }
                raw_defs.push((name.to_string(), value.clone()));
                seen.insert(name.to_string(), value);
            }
        }
    }

    // Helper to resolve a constant recursively
    fn resolve<'a>(name: &str, emitted: &'a HashMap<String, String>) -> Option<String> {
        let mut current = name;
        let mut count = 0;
        while let Some(val) = emitted.get(current) {
            if val.starts_with('"') && val.ends_with('"') {
                return Some(val.clone());
            }
            if let Ok(_) = val.parse::<i32>() {
                return Some(val.clone());
            }
            if let Ok(_) = val.parse::<f32>() {
                return Some(val.clone());
            }
            current = val;
            count += 1;
            if count > 10 {
                break;
            } // prevent infinite loop
        }
        None
    }

    // Second pass: resolve references and emit Rust constants
    let mut emitted = HashMap::new();
    for (name, val) in &raw_defs {
        // Omit type alias constants
        if val == "uint8_t" || val == "bool" || val == "size_t" {
            continue;
        }
        // Special-case EI_CLASSIFIER_SENSOR: always emit as i32
        if name == "EI_CLASSIFIER_SENSOR" {
            // Try to resolve recursively
            let resolved = if let Some(resolved) = resolve(val, &emitted) {
                resolved
            } else {
                val.clone()
            };
            if let Ok(num) = resolved.parse::<i32>() {
                out.push_str(&format!(
                    "pub const {}: i32 = {};
",
                    name, num
                ));
                emitted.insert(name.clone(), num.to_string());
            } else {
                out.push_str(&format!(
                    "// Could not resolve EI_CLASSIFIER_SENSOR as i32: {}\n",
                    resolved
                ));
            }
            continue;
        }
        // String constants
        if val.starts_with('"') && val.ends_with('"') {
            out.push_str(&format!(
                "pub const {}: &str = {};
",
                name, val
            ));
            emitted.insert(name.clone(), val.clone());
            continue;
        }
        // Numeric constants
        if let Ok(num) = val.parse::<i32>() {
            if num < 0 {
                out.push_str(&format!(
                    "pub const {}: i32 = {};
",
                    name, num
                ));
            } else {
                out.push_str(&format!(
                    "pub const {}: usize = {};
",
                    name, num
                ));
            }
            emitted.insert(name.clone(), val.clone());
            continue;
        }
        if let Ok(num) = val.parse::<f32>() {
            out.push_str(&format!(
                "pub const {}: f32 = {};
",
                name, num
            ));
            emitted.insert(name.clone(), val.clone());
            continue;
        }
        // Reference to another constant
        if let Some(resolved) = emitted.get(val) {
            // Use the resolved value and type
            if resolved.starts_with('"') && resolved.ends_with('"') {
                out.push_str(&format!(
                    "pub const {}: &str = {};
",
                    name, resolved
                ));
            } else if let Ok(num) = resolved.parse::<i32>() {
                if num < 0 {
                    out.push_str(&format!(
                        "pub const {}: i32 = {};
",
                        name, num
                    ));
                } else {
                    out.push_str(&format!(
                        "pub const {}: usize = {};
",
                        name, num
                    ));
                }
            } else if let Ok(num) = resolved.parse::<f32>() {
                out.push_str(&format!(
                    "pub const {}: f32 = {};
",
                    name, num
                ));
            } else {
                out.push_str(&format!(
                    "pub const {}: usize = {};
",
                    name, resolved
                ));
            }
            emitted.insert(name.clone(), resolved.clone());
            continue;
        }
        // Special case: EI_CLASSIFIER_SLICE_SIZE
        if name == "EI_CLASSIFIER_SLICE_SIZE" {
            // Try to resolve from other constants
            let raw_sample_count = emitted
                .get("EI_CLASSIFIER_RAW_SAMPLE_COUNT")
                .and_then(|v| v.parse::<usize>().ok())
                .unwrap_or(0);
            let slices_per_window = emitted
                .get("EI_CLASSIFIER_SLICES_PER_MODEL_WINDOW")
                .and_then(|v| v.parse::<usize>().ok())
                .unwrap_or(1);
            let value = raw_sample_count / slices_per_window;
            out.push_str(&format!(
                "pub const EI_CLASSIFIER_SLICE_SIZE: usize = {};
",
                value
            ));
            emitted.insert(name.clone(), value.to_string());
            continue;
        }
        // Special case: EI_CLASSIFIER_RESIZE_MODE
        if name == "EI_CLASSIFIER_RESIZE_MODE" {
            // This should resolve to EI_CLASSIFIER_RESIZE_SQUASH (3)
            out.push_str(
                "pub const EI_CLASSIFIER_RESIZE_MODE: usize = EI_CLASSIFIER_RESIZE_SQUASH;\n",
            );
            emitted.insert(name.clone(), "EI_CLASSIFIER_RESIZE_SQUASH".to_string());
            continue;
        }
        // Fallback: emit as a reference (may cause build error, but better than omitting)
        out.push_str(&format!("// Could not resolve: {} = {}\n", name, val));
    }

    // Add missing constants that are referenced but not defined in the header
    if !emitted.contains_key("EI_CLASSIFIER_RESIZE_SQUASH") {
        out.push_str("pub const EI_CLASSIFIER_RESIZE_SQUASH: usize = 3;\n");
    }
    if !emitted.contains_key("EI_CLASSIFIER_RESIZE_FIT_SHORTEST") {
        out.push_str("pub const EI_CLASSIFIER_RESIZE_FIT_SHORTEST: usize = 1;\n");
    }
    if !emitted.contains_key("EI_CLASSIFIER_RESIZE_FIT_LONGEST") {
        out.push_str("pub const EI_CLASSIFIER_RESIZE_FIT_LONGEST: usize = 2;\n");
    }
    if !emitted.contains_key("EI_CLASSIFIER_LAST_LAYER_YOLOV5") {
        out.push_str("pub const EI_CLASSIFIER_LAST_LAYER_YOLOV5: usize = 0;\n");
    }

    fs::write(out_path, out).expect("Failed to write model_metadata.rs");
}

fn main() {
    // Force rerun on every build
    println!("cargo:rerun-if-changed=build.rs");

    // Get the current working directory and construct absolute paths
    let manifest_dir = env::var("CARGO_MANIFEST_DIR").expect("CARGO_MANIFEST_DIR not set");
    let manifest_path = PathBuf::from(manifest_dir);

    println!("cargo:info=Manifest directory: {:?}", manifest_path);

    let model_header = manifest_path.join("model/model-parameters/model_metadata.h");
    let out_bindings = manifest_path.join("src/bindings.rs");
    let _out_metadata = manifest_path.join("src/model_metadata.rs");

    // Check if we have a valid model structure - only look for actual model components
    let sdk_dir = manifest_path.join("model/edge-impulse-sdk");
    let model_parameters_dir = manifest_path.join("model/model-parameters");
    let tflite_model_dir = manifest_path.join("model/tflite-model");

    // Check if we have the essential model components
    let has_valid_model = sdk_dir.exists() && model_parameters_dir.exists() && tflite_model_dir.exists();

    // If we have a valid model, copy the FFI glue files to set up the build environment
    if has_valid_model {
        build_helpers::copy_ffi_glue("model");
    }

    if has_valid_model {
        println!("cargo:info=Valid Edge Impulse model found, generating real bindings...");

        // Generate real bindings using bindgen
        let wrapper_header = manifest_path.join("model/edge_impulse_wrapper.h");
        let bindings = bindgen::Builder::default()
            .header(wrapper_header.to_str().unwrap())
            .clang_arg("-xc++")
            .clang_arg("-std=c++17")
            .clang_arg("-Imodel")
            .clang_arg("-Imodel/edge-impulse-sdk")
            .rustified_enum(".*")
            .default_enum_style(bindgen::EnumVariation::Rust {
                non_exhaustive: false,
            })
            .prepend_enum_name(false)
            .translate_enum_integer_types(true)
            .derive_copy(true)
            .derive_debug(true)
            .derive_default(true)
            .derive_eq(true)
            .derive_hash(true)
            .derive_partialeq(true)
            .derive_partialord(true)
            .derive_ord(true)
            .allowlist_type("ei_impulse_handle_t")
            .allowlist_type("ei_impulse_result_t")
            .allowlist_type("ei_feature_t")
            .allowlist_type("ei_signal_t")
            .allowlist_type("EI_IMPULSE_ERROR")
            .allowlist_type("ei_impulse_result_classification_t")
            .allowlist_type("ei_impulse_result_bounding_box_t")
            .allowlist_type("ei_impulse_result_timing_t")
            .allowlist_function("ei_ffi_run_classifier_init")
            .allowlist_function("ei_ffi_run_classifier_deinit")
            .allowlist_function("ei_ffi_init_impulse")
            .allowlist_function("ei_ffi_run_classifier")
            .allowlist_function("ei_ffi_run_classifier_continuous")
            .allowlist_function("ei_ffi_run_inference")
            .allowlist_function("ei_ffi_signal_from_buffer")
            .generate()
            .expect("Unable to generate bindings");

        bindings
            .write_to_file(&out_bindings)
            .expect("Couldn't write bindings!");

        // Add allow attributes to suppress warnings in generated bindings
        let bindings_content = std::fs::read_to_string(&out_bindings).expect("Failed to read generated bindings");
        let modified_content = format!(
            "#![allow(non_camel_case_types, non_snake_case, non_upper_case_globals)]\n{}",
            bindings_content
        );
        std::fs::write(&out_bindings, modified_content).expect("Failed to write modified bindings");

        // Generate model metadata
        if model_header.exists() {
            extract_and_write_model_metadata();
        } else {
            println!("cargo:warning=Model metadata header not found, skipping metadata generation");
        }

        println!("cargo:info=Real bindings generated successfully!");
    } else {
        println!("cargo:warning=No valid Edge Impulse model found, skipping bindings and metadata generation.");
    }

    // Check if we should clean the model folder
    if env::var("CLEAN_MODEL").is_ok() {
        clean_model_folder();
        return;
    }

    // Define model directory and build directory for use throughout the function
    let model_dir = "model";
    let cpp_dir = PathBuf::from(model_dir);
    let build_dir = cpp_dir.join("build");

        // If we have a valid model, we need to build the C++ library
    if has_valid_model {
        build_helpers::copy_ffi_glue(model_dir);

        // Create build directory if it doesn't exist
        std::fs::create_dir_all(&build_dir).expect("Failed to create build directory");
    }

    // Check if we need full TensorFlow Lite
    // Only USE_FULL_TFLITE is supported
    let use_full_tflite = env::var("USE_FULL_TFLITE").is_ok();

    // Detect platform target
    let target_platform = if env::var("TARGET_MAC_ARM64").is_ok() {
        "mac-arm64"
    } else if env::var("TARGET_MAC_X86_64").is_ok() {
        "mac-x86_64"
    } else if env::var("TARGET_LINUX_X86").is_ok() {
        "linux-x86"
    } else if env::var("TARGET_LINUX_AARCH64").is_ok() {
        "linux-aarch64"
    } else if env::var("TARGET_LINUX_ARMV7").is_ok() {
        "linux-armv7"
    } else if env::var("TARGET_JETSON_NANO").is_ok() {
        "linux-jetson-nano"
    } else if env::var("TARGET_JETSON_ORIN").is_ok() {
        "linux-aarch64" // Jetson Orin uses aarch64
    } else if env::var("TARGET_RENESAS_RZV2L").is_ok() {
        "linux-aarch64" // Renesas RZ/V2L uses aarch64
    } else if env::var("TARGET_RENESAS_RZG2L").is_ok() {
        "linux-aarch64" // Renesas RZ/G2L uses aarch64
    } else if env::var("TARGET_AM68PA").is_ok() || env::var("TARGET_AM62A").is_ok() || env::var("TARGET_AM68A").is_ok() || env::var("TARGET_TDA4VM").is_ok() {
        "linux-aarch64" // TI TDA4VM variants use aarch64
    } else {
        // Auto-detect based on current system
        if cfg!(target_os = "macos") {
            if cfg!(target_arch = "aarch64") {
                "mac-arm64"
            } else {
                "mac-x86_64"
            }
        } else if cfg!(target_os = "linux") {
            if cfg!(target_arch = "aarch64") {
                "linux-aarch64"
            } else if cfg!(target_arch = "arm") {
                "linux-armv7"
            } else {
                "linux-x86"
            }
        } else {
            "linux-x86" // default fallback
        }
    };

    // Detect additional backend/accelerator support
    let use_tvm = env::var("USE_TVM").is_ok();
    let use_onnx = env::var("USE_ONNX").is_ok();
    let use_qualcomm_qnn = env::var("USE_QUALCOMM_QNN").is_ok();
    let use_ethos = env::var("USE_ETHOS").is_ok();
    let use_akida = env::var("USE_AKIDA").is_ok();
    let use_memryx = env::var("USE_MEMRYX").is_ok();
    let link_tflite_flex = env::var("LINK_TFLITE_FLEX_LIBRARY").is_ok();
    let use_memryx_software = env::var("EI_CLASSIFIER_USE_MEMRYX_SOFTWARE").is_ok();

    // Get TensorRT version for Jetson builds
    let tensorrt_version = env::var("TENSORRT_VERSION").unwrap_or_else(|_| "8.5.2".to_string());

    // Get Python cross path for cross-compilation
    let python_cross_path = env::var("PYTHON_CROSS_PATH").ok();

    // Configure CMake with the required macros for C linkage
    let mut cmake_args = vec![
        "..".to_string(),
        "-DCMAKE_BUILD_TYPE=Release".to_string(),
        "-DEIDSP_SIGNAL_C_FN_POINTER=1".to_string(),
        "-DEI_C_LINKAGE=1".to_string(),
        "-DBUILD_SHARED_LIBS=OFF".to_string(), // Build static library
    ];

    if use_full_tflite {
        cmake_args.push("-DEI_CLASSIFIER_USE_FULL_TFLITE=1".to_string());
        cmake_args.push(format!("-DTARGET_PLATFORM={}", target_platform));
        println!("cargo:info=Building with full TensorFlow Lite for platform: {}", target_platform);
    } else {
        println!("cargo:info=Building with TensorFlow Lite Micro");
    }

    // Pass additional backend/accelerator flags
    if use_tvm {
        cmake_args.push("-DUSE_TVM=1".to_string());
        println!("cargo:info=Building with Apache TVM support");
    }
    if use_onnx {
        cmake_args.push("-DUSE_ONNX=1".to_string());
        println!("cargo:info=Building with ONNX Runtime support");
    }
    if use_qualcomm_qnn {
        cmake_args.push("-DUSE_QUALCOMM_QNN=1".to_string());
        println!("cargo:info=Building with Qualcomm QNN support");
    }
    if use_ethos {
        cmake_args.push("-DUSE_ETHOS=1".to_string());
        println!("cargo:info=Building with ARM Ethos support");
    }
    if use_akida {
        cmake_args.push("-DUSE_AKIDA=1".to_string());
        println!("cargo:info=Building with BrainChip Akida support");
    }
    if use_memryx {
        cmake_args.push("-DUSE_MEMRYX=1".to_string());
        println!("cargo:info=Building with MemryX support");
    }
    if link_tflite_flex {
        cmake_args.push("-DLINK_TFLITE_FLEX_LIBRARY=1".to_string());
        println!("cargo:info=Linking TensorFlow Lite Flex library");
    }
    if use_memryx_software {
        cmake_args.push("-DEI_CLASSIFIER_USE_MEMRYX_SOFTWARE=1".to_string());
        println!("cargo:info=Using MemryX software mode");
    }

    // Pass TensorRT version for Jetson builds
    cmake_args.push(format!("-DTENSORRT_VERSION={}", tensorrt_version));

    // Pass Python cross path if specified
    if let Some(ref path) = python_cross_path {
        cmake_args.push(format!("-DPYTHON_CROSS_PATH={}", path));
    }

                // If we have a valid model, check if we need to build the C++ library
    if has_valid_model {
        // Check if the library already exists
        let lib_path = build_dir.join("libedge-impulse-sdk.a");
        if !lib_path.exists() {
            println!("cargo:info=Library not found, building C++ library...");

            let cmake_status = Command::new("cmake")
                .args(&cmake_args)
                .current_dir(&build_dir)
                .status()
                .expect("Failed to run cmake configure");

            if !cmake_status.success() {
                panic!("CMake configuration failed");
            }

            // Build the library
            let make_status = Command::new("make")
                .arg("-j")
                .arg(&env::var("NUM_JOBS").unwrap_or_else(|_| "4".to_string()))
                .current_dir(&build_dir)
                .status()
                .expect("Failed to run make");

            if !make_status.success() {
                panic!("Make build failed");
            }
        } else {
            println!("cargo:info=Library already exists, skipping build");
        }

        // Diagnostic: print contents of build directory
        let entries = std::fs::read_dir(&build_dir).expect("Failed to read build directory");
        println!("Contents of {}:", build_dir.display());
        for entry in entries {
            let entry = entry.expect("Failed to read entry");
            println!("  {}", entry.file_name().to_string_lossy());
        }
    }

    // If we have a valid model, always set up library linking (regardless of whether we built it or not)
    if has_valid_model {
        println!("cargo:info=Setting up library linking for valid model");
        println!("cargo:info=Build directory: {}", build_dir.display());

        // Tell Cargo where to find the built library - use absolute path
        let absolute_build_dir = build_dir.canonicalize().expect("Failed to get absolute path");
        println!("cargo:rustc-link-search=native={}", absolute_build_dir.display());

        // Link against the Edge Impulse SDK library
        // The library name will depend on what CMake generates, typically something like "edge-impulse-sdk"
        println!("cargo:rustc-link-lib=static=edge-impulse-sdk");

        // Link against C++ standard library
        println!("cargo:rustc-link-lib=c++");

        // Re-run if any of the source files change
        println!("cargo:rerun-if-changed={}/CMakeLists.txt", model_dir);
        println!(
            "cargo:rerun-if-changed={}/edge_impulse_wrapper.h",
            model_dir
        );
        println!("cargo:rerun-if-changed={}/edge-impulse-sdk", model_dir);
        println!("cargo:rerun-if-changed={}/model-parameters", model_dir);
        println!("cargo:rerun-if-changed={}/tflite-model", model_dir);

        println!("cargo:info=Library linking setup complete");
    } else {
        println!("cargo:info=No valid model found, skipping library linking");
    }

    // Only extract model metadata if we have a valid model
    if has_valid_model {
        extract_and_write_model_metadata();
    }
}


